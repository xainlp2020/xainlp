<!-- <div class="w3-content w3-margin-top" style="max-width:1500px;"></div> -->
<div class = w3-light-grey>
<div class="w3-content w3-padding w3-light-grey def-container">
    <mat-card class="w3-margin def-section">
      <mat-card-title>
        Taxonomy
      </mat-card-title>
      <mat-card-content class="w3-content w3-center">
        <img src="assets/img/taxonomy.svg">
      </mat-card-content>
      
    </mat-card>

    <!-------------------->
    <!-- EXPLAINABILITY -->
    <!-------------------->

    <mat-card class="w3-margin def-section">
      <mat-card-title>
        Explainability Techniques
      </mat-card-title>
      <mat-card-content>
        <div fxLayout="row wrap" class="w3-padding">


          <mat-card >
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Feature Importance</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Prediction explanations are derived from the
                 importance scores of different features used
                 in the NLP model to output the final prediction.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Surrogate Model</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Explains model predictions by learning a second model,
                which is usually more explainable than the original
                model, as a proxy.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Example-Driven</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                A particular prediction of an input instance is explained
                by identifying and presenting other instances, usually from
                available labeled data, that are semantically similar to the input instance.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Provenance</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                The explanation is an illustration of the entire prediction
                derivation process, which is an intuitive and effective
                explainability technique when the final prediction consists
                of a series of reasoning steps.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Induction</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
              Explanations are generated by inducing human-readable
              representations, such as rules, trees and programs.
              </div>
            </mat-card-content>
          </mat-card>
        </div>

      </mat-card-content>

    </mat-card>

    <!------------------->
    <!-- VISUALIZATION -->
    <!------------------->

    <mat-card class="w3-margin def-section">
      <mat-card-title>
        Visualization Techniques
      </mat-card-title>
      <mat-card-content>

        <div class="w3-padding">

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Saliency - Heatmap</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="280px" style="margin-right:50px; margin-left:8px;" src="assets/img/saliency-heatmap-word-alignment.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://arxiv.org/pdf/1409.0473.pdf">
                  (Bahdanau et al.,2015)</a>
                </div>
            </div>
            <div style="display: flex; align-items: center;">
              <span class="text">
                Saliency has been primarily used to visualize the importance
                scores  of  different  types  of  elements  in  XAI  learning
                systems,  such  as  showing input-output word alignment.
              </span>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Saliency - Highlighting</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/saliency-highlighting.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://www.aclweb.org/anthology/N18-1100/">
                  (Mullenbach et al., 2018)</a>
                </div>
            </div>
            <div style="display: flex; align-items: center;">
              <span class="text">
                Saliency has been primarily used to visualize the importance
                scores of different types of elements in XAI learning
                systems, such as highlighting words in input text.
              </span>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Raw Declarative Representation - Rules</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-declarative-rules.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://arxiv.org/pdf/1905.00563">
                  (Pezeshkpour et al., 2019)</a>
                </div>
            </div>
            <div style="display: flex; align-items: center;">
              <span class="text">
                This visualization technique directly presents the learned
                declarative representations, such as logic rules.
              </span>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Raw Declarative Representation - Programs</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-declarative-program.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://doi.org/10.18653/v1/N19-1245">
                  (Amini et al., 2019)</a>
                </div>
            </div>
            <div style="display: flex; align-items: top;">
              <span class="text">
                This visualization technique directly presents the learned
                declarative representations, such as programs.
              </span>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Natural Language</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/natural-language-QUINT.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://www.aclweb.org/anthology/D17-2011">
                  (Abujabal et al., 2017)</a>
                </div>
            </div>
            <div style="display: flex; align-items: center;">
              <span class="text">
                The explanation is verbalized in human-comprehensible
                natural language, which can be generated, for example,
                by using simple template-based approaches.
              </span>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title>Raw Examples</mat-card-title>
            </mat-card-header>
            <mat-card-content fxLayout="column" style="display:flex;">
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-examples.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://doi.org/10.18653/v1/D19-1415">
                  (Croce et al., 2019)</a>
                </div>
            </div>
            <div style="display: flex; align-items: top;">
              <span class="text">
                This visualization technique presents raw examples, usually from
                the training data, to motivate the explanation.
              </span>
            </div>
            </mat-card-content>
          </mat-card>


        </div>

      </mat-card-content>

    </mat-card>

    <!---------------->
    <!-- EVALUATION -->
    <!---------------->

    <mat-card class="w3-margin def-section">
      <mat-card-title>
        Evaluation Metrics
      </mat-card-title>
      <mat-card-content>

        <div fxLayout="row wrap" class="w3-padding">


          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Informal Examination</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                A presentation of no more than a few generated explanations,
                usually accompanied by a high-level discussion on how
                they align with human intuition.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Comparison to Ground Truth</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Compare generated explanations to ground truth data in an effort to
                quantify the performance of explainability techniques. Employed metrics
                vary based on task and explainability technique.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="w3-margin-top">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Human Evaluation</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Humans directly evaluate the effectiveness of the generated
                explanations via one or more user studies.
              </div>
            </mat-card-content>
          </mat-card>

          </div>

      </mat-card-content>

    </mat-card>



  </div>

</div>
