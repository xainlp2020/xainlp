<!-- <div class="w3-content w3-margin-top" style="max-width:1500px;"></div> -->
<div>

<!--<div class="w3-content w3-padding w3-light-grey def-container"> -->
<div class="def-container">
	<div class="page-title">
		Definitions
	</div>
	<div class="page-content">
		We have identified 4 major dimensions on which explainability approaches can be classified. We summarize below the common approaches encountered in the literature for each of the 4 dimensions.
	</div>




<!-- Tabs -->
<mat-tab-group animationDuration="0ms">

    <!-------------------->
    <!-- EXPLANATION TYPE -->
    <!-------------------->

   <mat-tab label="Explanation Types">	
<!-- 
     <ng-template mat-tab-label>
      <span class="tab-label">Explanation Types</span><br>
      <span class="tab-desc">What is the type of the explanation</span>
	</ng-template>
-->
    <mat-card class="def-section">
	  <!--
      <mat-card-title class="def-title">
        Explanation Types
      </mat-card-title>
      -->
      <mat-card-content>
      <div class="def-subtitle">
      	What is the type of the explanation
      </div>
    <div class="card-container d-flex flex-wrap">
          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Local Post-Hoc</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Explain a single prediction by performing additional operations (<b>after</b> the model has emitted a prediction).
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Local Self-Explaining</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Explain a single prediction using the model itself (calculated from information made available from the model <b>as part of</b> making the prediction).
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Global Post-Hoc</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Perform additional operations to explain the entire model's predictive reasoning.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Global Self-Explaining</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Use the predictive model itself to explain the entire model's predictive reasoning (a.k.a. directly interpretable model).
              </div>
            </mat-card-content>
          </mat-card>
    
    </div>
	</mat-card-content>
	</mat-card>
  </mat-tab>

    <!-------------------->
    <!-- EXPLAINABILITY -->
    <!-------------------->

  <mat-tab label="Explainability Techniques">
    <mat-card class="def-section">
      <!--
      <mat-card-title class="def-title">
        Explainability Techniques
      </mat-card-title>
      -->
      <mat-card-content class="def-subtitle">
        <div>
      	  How are explanations generated
        </div>      
        <div class="card-container d-flex flex-wrap">

        <mat-card class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Feature Importance</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Prediction explanations are derived from the
                 importance scores of different features used
                 in the NLP model to output the final prediction.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Surrogate Model</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Explain model predictions by learning a second model,
                which is usually more explainable than the original
                model, as a proxy.
              </div>
            </mat-card-content>
          </mat-card>
          
          <mat-card class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Example-Driven</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                A particular prediction of an input instance is explained
                by identifying and presenting other instances, usually from
                available labeled data, that are semantically similar to the input instance.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Provenance</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                The explanation is an illustration of the entire prediction
                derivation process, which is an intuitive and effective
                explainability technique when the final prediction consists
                of a series of reasoning steps.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Induction</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
              Explanations are generated by inducing human-readable
              representations, such as rules, trees and programs.
              </div>
            </mat-card-content>
          </mat-card>

    </div>
    
    </mat-card-content>
    </mat-card>
  </mat-tab>

    <!-------------------->
    <!-- VISUALIZATION -->
    <!-------------------->

  <mat-tab label="Visualization Techniques">
    <mat-card class="def-section">
      <!--
      <mat-card-title class="def-title">
        Visualization Techniques
      </mat-card-title>
      -->
      <mat-card-content>
         <div class="def-subtitle">
           How are explanations visualized
         </div>
         <div class="card-container d-flex flex-wrap">

          <mat-card class="col-md-5 def-card" fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Saliency - Heatmap</mat-card-title>
            </mat-card-header>
            <mat-card-content>
            <div style="display: flex; align-items: center; margin-bottom: 12px;">
              <span class="text">
                Visualize importance scores of different types of elements (such as input-output word alignment) through a heatmap.
              </span>
            </div>
              <div>
                <img width="280px" style="margin-right:50px; margin-left:8px;" src="assets/img/saliency-heatmap-word-alignment.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://arxiv.org/pdf/1409.0473.pdf">
                  (Bahdanau et al.,2015)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-md-5 def-card"  fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Saliency - Highlighting</mat-card-title>
            </mat-card-header>
            <mat-card-content>
            <div style="display: flex; align-items: center; margin-bottom: 12px;">
              <span class="text">
                Visualize importance scores of different types of elements by highlighting words in input text.
              </span>
            </div>
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/saliency-highlighting.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://www.aclweb.org/anthology/N18-1100/">
                  (Mullenbach et al., 2018)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-md-5 def-card"  fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Raw Declarative Representation - Rules</mat-card-title>
            </mat-card-header>
            <mat-card-content>
			  <div style="display: flex; align-items: center; margin-bottom: 12px;">
                <span class="text">
                  Directly present learned logic rules.
                </span>
              </div>
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-declarative-rules.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://arxiv.org/pdf/1905.00563">
                  (Pezeshkpour et al., 2019)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-md-5 def-card"  fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Raw Declarative Representation - Programs</mat-card-title>
            </mat-card-header>
            <mat-card-content>
              <div style="display: flex; align-items: top; margin-bottom: 12px;">
                <span class="text">
                  Directly present learned programs.
                </span>
              </div>
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-declarative-program.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://doi.org/10.18653/v1/N19-1245">
                  (Amini et al., 2019)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-md-5 def-card"  fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Natural Language</mat-card-title>
            </mat-card-header>
            <mat-card-content>
            <div style="display: flex; align-items: center; margin-bottom: 12px;">
              <span class="text">
                Verbalize explanation in human-comprehensible
                natural language.
              </span>
            </div>
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/natural-language-QUINT.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://www.aclweb.org/anthology/D17-2011">
                  (Abujabal et al., 2017)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>

          <mat-card class="col-md-5 def-card"  fxFlexAlign="stretch">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Raw Examples</mat-card-title>
            </mat-card-header>
            <mat-card-content>
            <div style="display: flex; align-items: top; margin-bottom: 12px;">
              <span class="text">
                Presents raw examples, usually from
                the training data, to motivate the explanation.
              </span>
            </div>
              <div>
                <img width="320px" style="margin:8px;" src="assets/img/raw-examples.png">
                <div class="cite">
                  <a target="_blank" rel="noopener noreferrer"
                  href="https://doi.org/10.18653/v1/D19-1415">
                  (Croce et al., 2019)</a>
                </div>
            </div>
            </mat-card-content>
          </mat-card>


	</div>
	</mat-card-content>
	</mat-card>	
  </mat-tab>

    <!-------------------->
    <!-- EVALUATION -->
    <!-------------------->	

  <mat-tab label="Evaluation Techniques">	
    <mat-card class="def-section">
      <!--
      <mat-card-title class="def-title">
        Evaluation Techniques
      </mat-card-title>
      -->
      <mat-card-content class="def-subtitle">
      <div>How are explainations evaluated</div>
    <div class="card-container d-flex flex-wrap">

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Informal Examination</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                A presentation of no more than a few generated explanations,
                usually accompanied by a high-level discussion on how
                they align with human intuition.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Comparison to Ground Truth</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Compare generated explanations to ground truth data in an effort to
                quantify the performance of explainability techniques. Employed metrics
                vary based on task and explainability technique.
              </div>
            </mat-card-content>
          </mat-card>

          <mat-card  class="col-sm-3 def-card">
            <mat-card-header class="title">
              <mat-card-title class="w3-large">Human Evaluation</mat-card-title>
            </mat-card-header>
             <mat-card-content>
              <div class="text">
                Humans directly evaluate the effectiveness of the generated
                explanations via one or more user studies.
              </div>
            </mat-card-content>
          </mat-card>
    
    </div>
	</mat-card-content>
	</mat-card>
  </mat-tab>
</mat-tab-group>

</div>

</div>
