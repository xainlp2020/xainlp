<div class="w3-margin-top w3-round w3-content w3-padding" style="width:90%">
  <div class="page-title">
  	XAI for Natural Language Processing
  </div>

  <div>
    <span class="w3-margin-top w3-large">Summarizing the state of AI Explainability for NLP</span>

	<hr>

	<h4 style="margin-top: 20px">Overview</h4>
	
	<div class="page-content">
	This web-site summarizes the state of AI explainability based on our survey and a technical tutorial appeared at AACL 2020:
  

  <div class="w3-margin-top w3-margin-left w3-light-grey w3-padding-small">
    <cite>
      Tutorial: Explainability for Natural Language Processing.
    </cite><br>
    Shipi Dhanorkar, Lucian Popa, Yunyao Li, Kun Qian, Christine T. Wolf, and Anbang Xu.<br>
    AACL-IJCNLP 2020.
  </div>
  <p class="w3-margin-left w3-padding-small"><a href="assets/AACL2020-xai-tutorial-final.pptx" target="_blank">TUTORIAL SLIDES</a></p>



  <div class="w3-margin-top w3-margin-left w3-light-grey w3-padding-small">
    <cite>
      A Survey of the State of Explainable AI for Natural Language Processing.
    </cite><br>
    Marina Danilevsky, Kun Qian, Ranit Aharonov, Yannis Katasis, Ban Kawas, Prithviraj Sen. <br>
    AACL-IJCNLP 2020.
  </div>

  <div class="w3-margin-top">Please cite our tutorial and/or our survey paper if you found this website and the slides useful:</div>
  <div class="w3-margin w3-padding">
    <div class="w3-margin-left w3-margin-right w3-padding-small w3-light-grey">
      <span>{{tutorial_citation_id}}</span><br>
      <span>{{tutorial_citation_title}}</span><br>
      <span>{{tutorial_citation_authors}}</span><br>
      <span>{{tutorial_citation_journal}}</span><br>
      <span>{{tutorial_citation_year}}</span><br>
    </div>

    <div class="w3-margin-left w3-margin-top  w3-margin-right w3-padding-small w3-light-grey">
      <span>{{survey_citation_id}}</span><br>
      <span>{{survey_citation_title}}</span><br>
      <span>{{survey_citation_authors}}</span><br>
      <span>{{survey_citation_journal}}</span><br>
      <span>{{survey_citation_year}}</span><br>
    </div>
  </div>
  <p class="w3-margin-top">To explore this web-site:</p>
	<ul>
		<li>Get familiar with the dimensions on which NLP explainability approaches can be classified by consulting the <a href="definitions">Definitions</a> </li>
		<li>Then find relevant NLP XAI publications by visualizing <a href="viz">Publication Statistics</a>, seeing a <a href="tree">Tabular List of Publications</a>, or <a href="search">Searching for Publications</a> </li>
	</ul>
	</div>

	<hr>
	
	<h4 style="margin-top: 20px">Literature Survey</h4>
	
	<div class="page-content">
	<p><span><i>Scope:</i></span>
	Our survey aims to demonstrate the recent advances of XAI research in NLP. To this end, we identified relevant papers published in major NLP conferences (ACL, NAACL, EMNLP, and COLING) between 2013 and 2019 (more recent papers are also in our pipeline).</p>

       <p><span><i>Search criteria for XAI papers for NLP:</i></span>
          To find relevant papers, we searched for titles containing (lemma-tized) terms related to XAI, such as “explainability”, “interpretability”, “transparent”, etc.  
          While this may ignore some related papers, we argue that representative papers are more likely to include such terms in their titles. In particular, 
          we assume that if authors consider explainability to be a major component of their work, they are more likely touse related keywords in the title of their work.</p>
        <p>Our search criteria yielded a set of {{total_search}} papers. During the paper review process we first verified whether each paper truly fell within the scope of the survey. 
          This process excluded {{total_search - total_num_papers}} papers, leaving us with a total of <b>{{total_num_papers}}</b> papers (by the end of 2019). 
          See some overall statistics in the <a routerLink="/viz">Cluster View</a> under Publications tab.
        </p>
        
        <!-- <div class="w3-row">
          <div class="w3-col s6 w3-center">
            <div class="w3-margin w3-content w3-border w3-small">
              <table class="w3-content w3-center table table-striped">
                <thead>
                <tr>
                  <th class="w3-grey" colspan="3" scope="col">Top 3 NLP Topics</th>
                </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Question Answering</td>
                    <td>Computational Social Science & Social Media</td>
                    <td>Syntax: Tagging, Chunking & Parsing</td>
                  </tr>
                  <tr>
                    <td>9 papers</td>
                    <td>6 papers</td>
                    <td>6 papers</td>
                  </tr>
                  
                </tbody>
              </table>
            </div>
          </div>
          <div class="w3-col s6 w3-center">
            <div class="w3-margin w3-border w3-content w3-small">
              <table class="w3-content w3-center table table-striped">
                <thead>
                <tr>
                  <th class="w3-grey" colspan="3" scope="col">Top 3 Conferences</th>
                </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>EMNLP</td>
                    <td>ACL</td>
                    <td>NAACL</td>
                  </tr>
                  <tr>
                    <td>22 papers</td>
                    <td>11 papers</td>
                    <td>9 papers</td>
                  </tr>
                  
                </tbody>
              </table>
            </div>
          </div>
          
        </div> -->
          
        
        
          <p><span><i>Reviewing methodology:</i></span>
          Each paper was then classified across four major aspects: <i>explainability</i>, <i>operations to enable explainability</i>, <i>visualization</i>, and <i>evaluation metrics</i>.
          To ensure a consistent classification, each paper was individually reviewed by at least two reviewers, consulting additional reviewers in the case of disagreement. 
          For simplicity of presentation, we label each paper with its main applicable category for each aspect. However, some papers may span multiple categories within an aspect, 
          though usually with varying degrees of emphasis. We include all relevant categories for every paper in website, with the goal of enablingthe readers of this survey to discover 
          interesting explainability techniques and ideas, even if they have not been fully developed in the respective publications. 
        </p>
    </div>
 	
	<hr>
	
	<h4 style="margin-top: 20px;">Adding New Papers</h4>
	
	<div class="page-content">
    <p>If you are aware of other papers that should be included, please submit them through the <a href="newpapers">Add New Papers</a> link.</p>
	</div>

	<hr>

	<!-- <h4 style="margin-top: 20px">Citation</h4> -->
	<!-- <div class="page-content">	
	<p>To refer to this work, please cite:</p>
	</div>

    <div class="w3-margin-top w3-sand w3-padding-16">
      <i class="w3-padding">"A Survey of the State of Explainable AI for Natural Language Processing."</i><br>
      <span class="w3-padding">Anonymous authors from anonymous affliations.</span><br>
      <span class="w3-padding">venue ??. Pages ??-??</span><br>
    </div>

	<hr>	 -->

	<h4 style="margin-top: 20px">Contact</h4>
    
    <div class="page-content">
    For any other questions or comments, please contact us at 
      <address>
        <a href="mailto:xainlp2020@gmail.com">xainlp2020@gmail.com</a>
      </address>
    </div>
    
  </div>

</div>
  
  